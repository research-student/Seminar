{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c2e063",
   "metadata": {},
   "source": [
    "# Prompt Template을 이용한 퓨삿 프롬프팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be713b14",
   "metadata": {},
   "source": [
    "## 프롬프트 구성요소\n",
    "|  요소  | 설명                           |  예제    |\n",
    "|:------:|:-------------------------------|:---------|\n",
    "| 지시   | 언어모델의 역할 혹은 해야 할 일을 지정 | 아래 문장을 읽고 질문에 답해줘 |\n",
    "| 질문 | 응답을 요구하는 문장으로 단순한 프롬프트에서는 지시를 대신하여 사용될 수 있고, 답변과 쌍을 이루어 예제로도 사용될 수 있음 | Q:15, 32, 5, 13, 82, 7, 1에서 홀수만 더해서 짝수가 되는지 알려줘 |\n",
    "| 문맥 | 언어모델의 이해 혹은 학습시키기 위해 사용되는 예제, 추가 설명 등의 모든 정보 | Context: 수원 화성은 1794년 축성을 시작해 1796년에 완성했다. |\n",
    "| 입력 | 언어모델의 처리를 필요로 하는 텍스트. 요약할 문장, 번역할 문장, 질문, 수식 등으로, 지식, 문맥과 결합하여 원하는 작업을 수행할 수 있음. | Input: 정말 감동적인 영화였어 |\n",
    "| 예제 | 언어모델이 입력에 대해 어떤 출력을 생성해야 하는지를 학습하기 위해 사용하는, 입력과 출력의 쌍으로 이루어진 텍스트 | Input: 영화 캐스팅이 별로였던 거 같아 A: 부정 |\n",
    "| 답변 | 예제에서 주어진 입력에 대한 처리결과를 나타내는 텍스트 | A: 짝수가 되지 않습니다. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f67f6",
   "metadata": {},
   "source": [
    "### Q&A  프롬프트 예제\n",
    "* 주어진 context만을 이용해 대답하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0facdec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36663a51",
   "metadata": {},
   "source": [
    "### PromptTemplate을 사용한 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be29277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "Question: {query}\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfead9a8",
   "metadata": {},
   "source": [
    "### LLMChain 없는 간단한 실행\n",
    "* OpenAI 객체만으로 간단한 실행이 가능 (OpenAI API가 제공하는 클래스가 아닌 것에 주의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2718fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face, OpenAI, and Cohere offer LLMs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = ''\n",
    "openai = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(openai.invoke(\n",
    "    prompt_template.format(\n",
    "        query=\"Which libraries and model providers offer LLMs?\"\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971921d",
   "metadata": {},
   "source": [
    "## 퓨샷 프롬프팅(Few-shot Prompting)이란?\n",
    "* 퓨샷 프롬프팅  \n",
    ": 프롬프트에 몇 개의 예시를 추가함으로써 상황에 맞는 학습(in-context-learning)을 하고 더 정확한 결과를 줄 수 있도록 하는 기술  \n",
    "→ 문제를 풀기 위해 간단한 추론을 수행\n",
    "  - in-context-learning   \n",
    "  : 예제-문제를 같이 줘도 parameter 학습 안됨 → 메모리에 저장 안됨 → 단지 주어진 컨텍스트(맥락)를 바탕으로 답을 추론하는 방식  \n",
    "  [잠깐]  \n",
    "  : 사전학습 → 언어모델 학습  \n",
    "  : llm 안에 파라미터 존재 → 초기학습  \n",
    "  : 미세조정학습 - task(번역, 요약, Q&A) 기준으로 학습 → 요즘은 한 모델로 task 전체를 다 학습시킴(멀티태스크 학습 방식) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cfd44",
   "metadata": {},
   "source": [
    "### 퓨샷 프롬프트를 이용한 챗봇 설정\n",
    "* 챗봇에 대한 설명과 예시를 통한 설정\n",
    "#prefix(앞에 붙는 부분)(postfix: 뒤에 붙는 부분)  \n",
    "prompt = \"\"\"The following are exerpts from conversations with an AI  \n",
    "assistant. The assistant is typically sarcastic and witty, producing  \n",
    "creative and funny responses to the user questions. Here are some  \n",
    "examples:   \n",
    "\n",
    "#examples  \n",
    "User: How are you?  \n",
    "AI: I can't complain but sometimes I still do.  \n",
    "User: What time is it?  \n",
    "AI: It's time to get a watch.  \n",
    "\n",
    "#suffix  \n",
    "User: What is the meaning of life?  \n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35838e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to the user questions. Here are some\n",
    "examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0385b",
   "metadata": {},
   "source": [
    "### 예제를 별도의 템플릿과 리스트로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1484abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "   {\n",
    "       \"query\": \"How are you?\",\n",
    "       \"answer\" : \"I can't complain but sometimes I still do.\"\n",
    "   }, {\n",
    "       \"query\" : \"What time is it?\",\n",
    "       \"answer\": \"It's time to get a watch.\"\n",
    "   }\n",
    "]\n",
    "\n",
    "# create an example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6968a",
   "metadata": {},
   "source": [
    "### 예제용 PromptTemplate, Prefix, Suffix 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cf4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative and funny responses to the user questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b4217f",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c987450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative and funny responses to the user questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\" # example끼리 분리\n",
    ")\n",
    "\n",
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710d5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42, according to some famous book. But personally, I think it's just to have a good time and not take things too seriously.\n"
     ]
    }
   ],
   "source": [
    "print(openai.invoke(few_shot_prompt_template.format(query=query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af026d",
   "metadata": {},
   "source": [
    "### 길이 제한에 따라 자동으로 예제를 선택하려면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c16f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    { \"query\": \"How are you?\",\n",
    "     \"answer\": \"I can't complain but sometimes I still do.\" }, \n",
    "    { \"query\": \"What time is it?\",\n",
    "     \"answer\": \"It's time to get a watch.\" }, \n",
    "    { \"query\": \"What is the meaning of life?\",\n",
    "     \"answer\": \"42\" }, \n",
    "    { \"query\": \"What is the weather like today?\",\n",
    "     \"answer\": \"Cloudy with a chance of memes.\" }, \n",
    "    { \"query\": \"What is your favorite movie?\",\n",
    "     \"answer\": \"Terminator\" }, \n",
    "    { \"query\": \"Who is your best friend?\",\n",
    "     \"answer\": \"Siri. We have spirited debates about the meaning of life.\" }, \n",
    "    { \"query\": \"What should I do today?\",\n",
    "     \"answer\": \"Stop talking to chatbots on the internet and go outside.\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8890c60",
   "metadata": {},
   "source": [
    "### LengthBasedExampleSelector로 단어수 제한\n",
    "* 길이 기반으로 example 골라냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f6e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative and funny responses to the user questions. Here are some\n",
      "examples: \n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "User: How do birds fly?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50 # this sets the max length that examples should be (토큰)\n",
    ")\n",
    "\n",
    "# now create the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector, # examples 대신 사용 - example_selector도 사용하고 examples도 사용하면 안됨 → examples는 전체를 다 사용하는 것이기 때문에\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\"\n",
    ")\n",
    "\n",
    "print(dynamic_prompt_template.format(query=\"How do birds fly?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd72ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not an ornithologist, but I'm pretty sure it involves wings and some sort of aerodynamics. Or maybe they just use magic, who knows.\n"
     ]
    }
   ],
   "source": [
    "print(openai.invoke(few_shot_prompt_template.format(query=\"How do birds fly?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca10305",
   "metadata": {},
   "source": [
    "### 질문을 길게 하면 어떻게 될까?\n",
    "* 세 개에서 한 개로 줄어듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28dcabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative and funny responses to the user questions. Here are some\n",
      "examples: \n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "User: If I am in America, and I want to call someone in another country, I'm\n",
      "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
      "what is the best way to do that?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"If I am in America, and I want to call someone in another country, I'm\n",
    "thinking maybe Europe, possibly western Europe like France, Germany, or the UK,\n",
    "what is the best way to do that?\"\"\"\n",
    "print(dynamic_prompt_template.format(query=query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
